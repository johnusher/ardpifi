{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying letters\r\n",
    "\r\n",
    "This notebook contains a training script for a classifier that can recognize a few letters from a bitmap."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras import layers\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "%load_ext tensorboard"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Set of letters we want to recognized\r\n",
    "_LETTERS = 'MOCL'\r\n",
    "# A set of letters used to train the \"other\" category. These shouldn't look\r\n",
    "# similar to any of the letters in _LETTERS\r\n",
    "_OTHER_LETTERS = 'FHIKRTY'\r\n",
    "\r\n",
    "\r\n",
    "# Labels in the emnist/letters dataset that should be used for training.\r\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS + _OTHER_LETTERS]\r\n",
    "\r\n",
    "_WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\r\n",
    "_OTHER_LABEL = 0\r\n",
    "_NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\r\n",
    "_BATCH_SIZE = 32\r\n",
    "\r\n",
    "# load train and test dataset\r\n",
    "\r\n",
    "\r\n",
    "def load_dataset():\r\n",
    "    # load dataset\r\n",
    "    (train_ds, test_ds), ds_info = tfds.load(\r\n",
    "        name='emnist/letters',\r\n",
    "        split=['train', 'test'],\r\n",
    "        shuffle_files=True,\r\n",
    "        with_info=True,\r\n",
    "        as_supervised=True,\r\n",
    "        decoders={\r\n",
    "            # Don't decode images, the dataset will get filtered,\r\n",
    "            # and we shouldn't decode what we don't use.\r\n",
    "            'image': tfds.decode.SkipDecoding(),\r\n",
    "        })\r\n",
    "\r\n",
    "    train_ds = prepare(train_ds, ds_info)\r\n",
    "    test_ds = prepare(test_ds, ds_info)\r\n",
    "\r\n",
    "    return (train_ds, test_ds), ds_info\r\n",
    "\r\n",
    "\r\n",
    "def prepare(dataset, ds_info):\r\n",
    "    labels = tf.constant(_LABELS, dtype=tf.int64)\r\n",
    "    wanted_labels = tf.constant(_WANTED_LABELS, dtype=tf.int64)\r\n",
    "\r\n",
    "    @tf.function\r\n",
    "    def is_wanted(image, label):\r\n",
    "        \"\"\"Returns true if label is in _LABELS\"\"\"\r\n",
    "        del image  # unused\r\n",
    "        return tf.math.reduce_any(label == labels)\r\n",
    "\r\n",
    "    @tf.function\r\n",
    "    def map_entry(image, label):\r\n",
    "        \"\"\"Transforms the image into the form our classifier will expect.\"\"\"\r\n",
    "        decoded = ds_info.features['image'].decode_example(image)\r\n",
    "        # Convert image to floats\r\n",
    "        image = tf.cast(decoded, tf.float32) / 255\r\n",
    "        # Images in emnist are transposed. Bring them back into normal direction.\r\n",
    "        image = tf.transpose(image, perm=[1, 0, 2])\r\n",
    "        label = tf.cond(\r\n",
    "            tf.math.reduce_any(label == wanted_labels),\r\n",
    "            # Relabel entries that are in _LETTERS to the range [1, len(_LETTERS)]\r\n",
    "            lambda: tf.argmax(tf.equal(wanted_labels, label)) + 1,\r\n",
    "            # Relabel entries in _OTHER_LETTERS to 0.\r\n",
    "            lambda: tf.constant(_OTHER_LABEL, dtype=tf.int64))\r\n",
    "        return image, label\r\n",
    "\r\n",
    "    return (dataset.filter(is_wanted).cache().shuffle(1000).map(\r\n",
    "        map_entry).batch(_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))\r\n",
    "\r\n",
    "\r\n",
    "def define_model():\r\n",
    "    # Train with images that randomly rotated, in any direction. This is\r\n",
    "    # because we can't tell the direction the wand is held.\r\n",
    "    # If we could, we might get better classification by reducing the range of\r\n",
    "    # random rotation.\r\n",
    "    data_augmentation = tf.keras.Sequential([\r\n",
    "        layers.experimental.preprocessing.RandomRotation(\r\n",
    "            1, interpolation='nearest'),\r\n",
    "    ])\r\n",
    "    model = Sequential()\r\n",
    "    model.add(data_augmentation)\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(16, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform',\r\n",
    "                      input_shape=(28, 28, 1)))\r\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(32, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform'))\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(32, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform'))\r\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "    model.add(layers.Flatten())\r\n",
    "    model.add(\r\n",
    "        layers.Dense(50, activation='relu', kernel_initializer='he_uniform'))\r\n",
    "    model.add(layers.Dense(_NUM_CLASSES))\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\r\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "        metrics=['accuracy'],\r\n",
    "    )\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "# trains a model\r\n",
    "\r\n",
    "\r\n",
    "def train_model(train_ds, test_ds):\r\n",
    "    \"\"\"Trains the model, and outputs evaluation stats to TensorBoard.\"\"\"\r\n",
    "    model = define_model()\r\n",
    "    logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,\r\n",
    "                                                     histogram_freq=1,\r\n",
    "                                                     profile_batch='500,520')\r\n",
    "    # fit model\r\n",
    "    history = model.fit(train_ds,\r\n",
    "                        epochs=10,\r\n",
    "                        validation_data=test_ds,\r\n",
    "                        callbacks=[tboard_callback],\r\n",
    "                        class_weight=_label_weights(len(_LABELS),\r\n",
    "                                                    _WANTED_LABELS))\r\n",
    "    # evaluate model\r\n",
    "    _, acc = model.evaluate(test_ds)\r\n",
    "    print('> %.3f' % (acc * 100.0))\r\n",
    "    return model, acc, history\r\n",
    "\r\n",
    "\r\n",
    "# plot diagnostic learning curves\r\n",
    "\r\n",
    "\r\n",
    "def summarize_diagnostics(histories):\r\n",
    "    for i in range(len(histories)):\r\n",
    "        # plot loss\r\n",
    "        pyplot.subplot(2, 1, 1)\r\n",
    "        pyplot.title('Cross Entropy Loss')\r\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\r\n",
    "        pyplot.plot(histories[i].history['val_loss'],\r\n",
    "                    color='orange',\r\n",
    "                    label='test')\r\n",
    "        # plot accuracy\r\n",
    "        pyplot.subplot(2, 1, 2)\r\n",
    "        pyplot.title('Classification Accuracy')\r\n",
    "        pyplot.plot(histories[i].history['accuracy'],\r\n",
    "                    color='blue',\r\n",
    "                    label='train')\r\n",
    "        pyplot.plot(histories[i].history['val_accuracy'],\r\n",
    "                    color='orange',\r\n",
    "                    label='test')\r\n",
    "    pyplot.show()\r\n",
    "\r\n",
    "\r\n",
    "# summarize model performance\r\n",
    "\r\n",
    "\r\n",
    "def summarize_performance(scores):\r\n",
    "    # print summary\r\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' %\r\n",
    "          (np.mean(scores) * 100, np.std(scores) * 100, len(scores)))\r\n",
    "    # box and whisker plots of results\r\n",
    "    pyplot.boxplot(scores)\r\n",
    "    pyplot.show()\r\n",
    "\r\n",
    "\r\n",
    "# run the test harness for evaluating a model\r\n",
    "\r\n",
    "\r\n",
    "def run_training():\r\n",
    "    \"\"\"Runs training and shows learning curves.\"\"\"\r\n",
    "    # load dataset\r\n",
    "    (train_ds, test_ds), ds_info = load_dataset()\r\n",
    "    # evaluate model\r\n",
    "    model, score, history = train_model(train_ds, test_ds)\r\n",
    "    # learning curves\r\n",
    "    summarize_diagnostics([history])\r\n",
    "    # summarize estimated performance\r\n",
    "    summarize_performance([score])\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def _label_weights(total_num_labels, wanted_labels):\r\n",
    "    \"\"\"Reweight the label costs to account over represented OTHER label.\"\"\"\r\n",
    "    label_weights = {\r\n",
    "        l: 1.0 / (len(wanted_labels) + 1)\r\n",
    "        for l in range(len(wanted_labels) + 1)\r\n",
    "    }\r\n",
    "    label_weights[_OTHER_LABEL] = (1.0 /\r\n",
    "                                   ((len(wanted_labels) + 1) *\r\n",
    "                                    (total_num_labels - len(wanted_labels))))\r\n",
    "    return label_weights\r\n",
    "\r\n",
    "\r\n",
    "def softmax(x):\r\n",
    "    e_x = np.exp(x - np.max(x))\r\n",
    "    return e_x / e_x.sum()\r\n",
    "\r\n",
    "\r\n",
    "def blur(img_array):\r\n",
    "    kernel = np.array([1, 3, 1])\r\n",
    "    img_array = np.apply_along_axis(\r\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 0, img_array)\r\n",
    "    img_array = np.apply_along_axis(\r\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 1, img_array)\r\n",
    "    return img_array\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model = run_training()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\john\\tensorflow_datasets\\emnist\\balanced\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:01<00:00,  2.44 file/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1mDataset emnist downloaded and prepared to C:\\Users\\john\\tensorflow_datasets\\emnist\\balanced\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 17s 28ms/step - loss: 1.8832e-04 - accuracy: 0.9967 - val_loss: 8.3329e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 1.8933e-09 - accuracy: 1.0000 - val_loss: 8.0588e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 2.4496e-09 - accuracy: 1.0000 - val_loss: 7.5756e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 1.7509e-09 - accuracy: 1.0000 - val_loss: 7.1259e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 6.5227e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 1.6082e-09 - accuracy: 1.0000 - val_loss: 5.9556e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 8.9516e-10 - accuracy: 1.0000 - val_loss: 5.5194e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 1.2780e-09 - accuracy: 1.0000 - val_loss: 4.8709e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 10s 20ms/step - loss: 9.9512e-10 - accuracy: 1.0000 - val_loss: 4.3049e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 13s 24ms/step - loss: 7.3085e-10 - accuracy: 1.0000 - val_loss: 3.8485e-07 - val_accuracy: 1.0000\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 3.8485e-07 - accuracy: 1.0000\n",
      "> 100.000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: mean=100.000 std=0.000, n=1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "%tensorboard --logdir=logs"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Export the model to tflite.\r\n",
    "\r\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "tflite_model = converter.convert()\r\n",
    "# open('model.tflite', 'wb').write(tflite_model)\r\n",
    "\r\n",
    "modelSaveName = _LETTERS + '_'+ _OTHER_LETTERS+'.tflite'\r\n",
    "open(modelSaveName, 'wb').write(tflite_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\john\\AppData\\Local\\Temp\\tmp__onyn42\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\john\\AppData\\Local\\Temp\\tmp__onyn42\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "164740"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Reload the tflite model\r\n",
    "\r\n",
    "\r\n",
    "interpreter = tf.lite.Interpreter(modelSaveName)\r\n",
    "# interpreter = tf.lite.Interpreter('model.tflite')\r\n",
    "interpreter.allocate_tensors()\r\n",
    "input_tensor = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\r\n",
    "output_tensor = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\r\n",
    "def classify(letter_image):\r\n",
    "    input_tensor()[:] = letter_image\r\n",
    "    interpreter.invoke()\r\n",
    "    probabilities = softmax(output_tensor()[0])\r\n",
    "    index = np.argmax(probabilities)\r\n",
    "    if not index:\r\n",
    "        return 'UNKNOWN', probabilities[index]\r\n",
    "    return _LETTERS[index - 1],  probabilities[index]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Run the classifier on a few examples\r\n",
    "\r\n",
    "print('M letters')\r\n",
    "for i in range(3, 10):\r\n",
    "    image = Image.open(f\"evaluation/{i}_M.bmp\")\r\n",
    "    image = image.crop((0, 0, 28, 28))\r\n",
    "    np_image = np.array(image, np.float32)\r\n",
    "    np_image = np_image / 255.0\r\n",
    "    # Apply a blur to the input image to look more like the emnist training set.\r\n",
    "    np_image = blur(np_image)\r\n",
    "\r\n",
    "    pyplot.imshow(np_image, cmap='gray')\r\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\r\n",
    "    del image\r\n",
    "\r\n",
    "print('O letters')\r\n",
    "for i in range(3, 21):\r\n",
    "    image = Image.open(f\"evaluation/{i}_O.bmp\")\r\n",
    "    image = image.crop((0, 0, 28, 28))\r\n",
    "    np_image = np.array(image, np.float32)\r\n",
    "    np_image = np_image / 255.0\r\n",
    "    np_image = blur(np_image)\r\n",
    "    np_image = np_image / np.max(np_image)\r\n",
    "\r\n",
    "    pyplot.imshow(np_image, cmap='gray')\r\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\r\n",
    "    del image\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M letters\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'evaluation/3_M.bmp'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7100/1486144789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M letters'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"evaluation/{i}_M.bmp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnp_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'evaluation/3_M.bmp'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
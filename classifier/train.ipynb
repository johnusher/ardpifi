{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying letters\r\n",
    "\r\n",
    "This notebook contains a training script for a classifier that can recognize a few letters from a bitmap."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras import layers\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "%load_ext tensorboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set of letters we want to recognized\r\n",
    "_LETTERS = 'CDMNOS'\r\n",
    "# A set of letters used to train the \"other\" category. These shouldn't look\r\n",
    "# similar to any of the letters in _LETTERS\r\n",
    "_OTHER_LETTERS = 'FHIKRTY'\r\n",
    "# Labels in the emnist/letters dataset that should be used for training.\r\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS + _OTHER_LETTERS]\r\n",
    "\r\n",
    "_WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\r\n",
    "_OTHER_LABEL = 0\r\n",
    "_NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\r\n",
    "_BATCH_SIZE = 32\r\n",
    "\r\n",
    "# load train and test dataset\r\n",
    "\r\n",
    "\r\n",
    "def load_dataset():\r\n",
    "    # load dataset\r\n",
    "    (train_ds, test_ds), ds_info = tfds.load(\r\n",
    "        name='emnist/letters',\r\n",
    "        split=['train', 'test'],\r\n",
    "        shuffle_files=True,\r\n",
    "        with_info=True,\r\n",
    "        as_supervised=True,\r\n",
    "        decoders={\r\n",
    "            # Don't decode images, the dataset will get filtered,\r\n",
    "            # and we shouldn't decode what we don't use.\r\n",
    "            'image': tfds.decode.SkipDecoding(),\r\n",
    "        })\r\n",
    "\r\n",
    "    train_ds = prepare(train_ds, ds_info)\r\n",
    "    test_ds = prepare(test_ds, ds_info)\r\n",
    "\r\n",
    "    return (train_ds, test_ds), ds_info\r\n",
    "\r\n",
    "\r\n",
    "def prepare(dataset, ds_info):\r\n",
    "    labels = tf.constant(_LABELS, dtype=tf.int64)\r\n",
    "    wanted_labels = tf.constant(_WANTED_LABELS, dtype=tf.int64)\r\n",
    "\r\n",
    "    @tf.function\r\n",
    "    def is_wanted(image, label):\r\n",
    "        \"\"\"Returns true if label is in _LABELS\"\"\"\r\n",
    "        del image  # unused\r\n",
    "        return tf.math.reduce_any(label == labels)\r\n",
    "\r\n",
    "    @tf.function\r\n",
    "    def map_entry(image, label):\r\n",
    "        \"\"\"Transforms the image into the form our classifier will expect.\"\"\"\r\n",
    "        decoded = ds_info.features['image'].decode_example(image)\r\n",
    "        # Convert image to floats\r\n",
    "        image = tf.cast(decoded, tf.float32) / 255\r\n",
    "        # Images in emnist are transposed. Bring them back into normal direction.\r\n",
    "        image = tf.transpose(image, perm=[1, 0, 2])\r\n",
    "        label = tf.cond(\r\n",
    "            tf.math.reduce_any(label == wanted_labels),\r\n",
    "            # Relabel entries that are in _LETTERS to the range [1, len(_LETTERS)]\r\n",
    "            lambda: tf.argmax(tf.equal(wanted_labels, label)) + 1,\r\n",
    "            # Relabel entries in _OTHER_LETTERS to 0.\r\n",
    "            lambda: tf.constant(_OTHER_LABEL, dtype=tf.int64))\r\n",
    "        return image, label\r\n",
    "\r\n",
    "    return (dataset.filter(is_wanted).cache().shuffle(1000).map(\r\n",
    "        map_entry).batch(_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))\r\n",
    "\r\n",
    "\r\n",
    "def define_model():\r\n",
    "    # Train with images that randomly rotated, in any direction. This is\r\n",
    "    # because we can't tell the direction the wand is held.\r\n",
    "    # If we could, we might get better classification by reducing the range of\r\n",
    "    # random rotation.\r\n",
    "    data_augmentation = tf.keras.Sequential([\r\n",
    "        layers.experimental.preprocessing.RandomRotation(\r\n",
    "            1, interpolation='nearest'),\r\n",
    "    ])\r\n",
    "    model = Sequential()\r\n",
    "    model.add(data_augmentation)\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(16, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform',\r\n",
    "                      input_shape=(28, 28, 1)))\r\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(32, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform'))\r\n",
    "    model.add(\r\n",
    "        layers.Conv2D(32, (3, 3),\r\n",
    "                      activation='relu',\r\n",
    "                      kernel_initializer='he_uniform'))\r\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\r\n",
    "    model.add(layers.Flatten())\r\n",
    "    model.add(\r\n",
    "        layers.Dense(50, activation='relu', kernel_initializer='he_uniform'))\r\n",
    "    model.add(layers.Dense(_NUM_CLASSES))\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\r\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "        metrics=['accuracy'],\r\n",
    "    )\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "# trains a model\r\n",
    "\r\n",
    "\r\n",
    "def train_model(train_ds, test_ds):\r\n",
    "    \"\"\"Trains the model, and outputs evaluation stats to TensorBoard.\"\"\"\r\n",
    "    model = define_model()\r\n",
    "    logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,\r\n",
    "                                                     histogram_freq=1,\r\n",
    "                                                     profile_batch='500,520')\r\n",
    "    # fit model\r\n",
    "    history = model.fit(train_ds,\r\n",
    "                        epochs=10,\r\n",
    "                        validation_data=test_ds,\r\n",
    "                        callbacks=[tboard_callback],\r\n",
    "                        class_weight=_label_weights(len(_LABELS),\r\n",
    "                                                    _WANTED_LABELS))\r\n",
    "    # evaluate model\r\n",
    "    _, acc = model.evaluate(test_ds)\r\n",
    "    print('> %.3f' % (acc * 100.0))\r\n",
    "    return model, acc, history\r\n",
    "\r\n",
    "\r\n",
    "# plot diagnostic learning curves\r\n",
    "\r\n",
    "\r\n",
    "def summarize_diagnostics(histories):\r\n",
    "    for i in range(len(histories)):\r\n",
    "        # plot loss\r\n",
    "        pyplot.subplot(2, 1, 1)\r\n",
    "        pyplot.title('Cross Entropy Loss')\r\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\r\n",
    "        pyplot.plot(histories[i].history['val_loss'],\r\n",
    "                    color='orange',\r\n",
    "                    label='test')\r\n",
    "        # plot accuracy\r\n",
    "        pyplot.subplot(2, 1, 2)\r\n",
    "        pyplot.title('Classification Accuracy')\r\n",
    "        pyplot.plot(histories[i].history['accuracy'],\r\n",
    "                    color='blue',\r\n",
    "                    label='train')\r\n",
    "        pyplot.plot(histories[i].history['val_accuracy'],\r\n",
    "                    color='orange',\r\n",
    "                    label='test')\r\n",
    "    pyplot.show()\r\n",
    "\r\n",
    "\r\n",
    "# summarize model performance\r\n",
    "\r\n",
    "\r\n",
    "def summarize_performance(scores):\r\n",
    "    # print summary\r\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' %\r\n",
    "          (np.mean(scores) * 100, np.std(scores) * 100, len(scores)))\r\n",
    "    # box and whisker plots of results\r\n",
    "    pyplot.boxplot(scores)\r\n",
    "    pyplot.show()\r\n",
    "\r\n",
    "\r\n",
    "# run the test harness for evaluating a model\r\n",
    "\r\n",
    "\r\n",
    "def run_training():\r\n",
    "    \"\"\"Runs training and shows learning curves.\"\"\"\r\n",
    "    # load dataset\r\n",
    "    (train_ds, test_ds), ds_info = load_dataset()\r\n",
    "    # evaluate model\r\n",
    "    model, score, history = train_model(train_ds, test_ds)\r\n",
    "    # learning curves\r\n",
    "    summarize_diagnostics([history])\r\n",
    "    # summarize estimated performance\r\n",
    "    summarize_performance([score])\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def _label_weights(total_num_labels, wanted_labels):\r\n",
    "    \"\"\"Reweight the label costs to account over represented OTHER label.\"\"\"\r\n",
    "    label_weights = {\r\n",
    "        l: 1.0 / (len(wanted_labels) + 1)\r\n",
    "        for l in range(len(wanted_labels) + 1)\r\n",
    "    }\r\n",
    "    label_weights[_OTHER_LABEL] = (1.0 /\r\n",
    "                                   ((len(wanted_labels) + 1) *\r\n",
    "                                    (total_num_labels - len(wanted_labels))))\r\n",
    "    return label_weights\r\n",
    "\r\n",
    "\r\n",
    "def softmax(x):\r\n",
    "    e_x = np.exp(x - np.max(x))\r\n",
    "    return e_x / e_x.sum()\r\n",
    "\r\n",
    "\r\n",
    "def blur(img_array):\r\n",
    "    kernel = np.array([1, 3, 1])\r\n",
    "    img_array = np.apply_along_axis(\r\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 0, img_array)\r\n",
    "    img_array = np.apply_along_axis(\r\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 1, img_array)\r\n",
    "    return img_array\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = run_training()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%tensorboard --logdir=logs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Export the model to tflite.\r\n",
    "\r\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "tflite_model = converter.convert()\r\n",
    "open('model.tflite', 'wb').write(tflite_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reload the tflite model\r\n",
    "\r\n",
    "interpreter = tf.lite.Interpreter('model.tflite')\r\n",
    "interpreter.allocate_tensors()\r\n",
    "input_tensor = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\r\n",
    "output_tensor = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\r\n",
    "def classify(letter_image):\r\n",
    "    input_tensor()[:] = letter_image\r\n",
    "    interpreter.invoke()\r\n",
    "    probabilities = softmax(output_tensor()[0])\r\n",
    "    index = np.argmax(probabilities)\r\n",
    "    if not index:\r\n",
    "        return 'UNKNOWN', probabilities[index]\r\n",
    "    return _LETTERS[index - 1],  probabilities[index]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the classifier on a few examples\r\n",
    "\r\n",
    "print('M letters')\r\n",
    "for i in range(3, 10):\r\n",
    "    image = Image.open(f\"evaluation/{i}_M.bmp\")\r\n",
    "    image = image.crop((0, 0, 28, 28))\r\n",
    "    np_image = np.array(image, np.float32)\r\n",
    "    np_image = np_image / 255.0\r\n",
    "    # Apply a blur to the input image to look more like the emnist training set.\r\n",
    "    np_image = blur(np_image)\r\n",
    "\r\n",
    "    pyplot.imshow(np_image, cmap='gray')\r\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\r\n",
    "    del image\r\n",
    "\r\n",
    "print('O letters')\r\n",
    "for i in range(3, 21):\r\n",
    "    image = Image.open(f\"evaluation/{i}_O.bmp\")\r\n",
    "    image = image.crop((0, 0, 28, 28))\r\n",
    "    np_image = np.array(image, np.float32)\r\n",
    "    np_image = np_image / 255.0\r\n",
    "    np_image = blur(np_image)\r\n",
    "    np_image = np_image / np.max(np_image)\r\n",
    "\r\n",
    "    pyplot.imshow(np_image, cmap='gray')\r\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\r\n",
    "    del image\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pyenv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "63e09749c7068a9676db1504407c7462e168c9c336bea5b73bf93df551cd59d4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}